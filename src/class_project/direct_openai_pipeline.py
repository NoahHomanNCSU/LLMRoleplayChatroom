import openai
import pandas as pd
import re
import json
from datetime import datetime
import tiktoken
import time
from openai import RateLimitError

# === CONFIG ===
api_key = "api_key"
csv_file = "src/class_project/backstories_filtered.csv"
topics_file = "src/class_project/topics.txt"
output_file = "persona_outputs.json"

client = openai.OpenAI(api_key=api_key)
enc = tiktoken.encoding_for_model("gpt-4")
logit_bias = {}

# === Ban all dash-like characters
for dash_char in ["-", "‚Äì", "‚Äî"]:
    for token in enc.encode(dash_char):
        logit_bias[token] = -100

max_tokens = 2000
current_year = str(datetime.now().year)

# === Retry wrapper for rate limits ===
def call_with_backoff(func, *args, **kwargs):
    retries = 0
    while True:
        try:
            return func(*args, **kwargs)
        except RateLimitError:
            wait_time = 2 ** retries
            print(f"‚ö†Ô∏è Rate limit hit. Retrying in {wait_time}s...")
            time.sleep(wait_time)
            retries += 1

# === Load topics ===
with open(topics_file, "r") as f:
    topics = [line.strip() for line in f if line.strip() and not line.lower().startswith("generated cocktail") and not re.match(r"^\d+\.", line)][:10]

# === Load 20 random character sheets ===
df = pd.read_csv(csv_file)
character_rows = df.sample(n=15).itertuples(index=False)

# === Output container ===
results = {}

# === Main Loop ===
for row in character_rows:
    raw_text = row.age_category_4_llm_parsing_prompt
    match = re.search(r"Answer:\s*(.+?)\s*(?:\nQuestion:|$)", raw_text, re.DOTALL)
    if not match:
        continue

    character_sheet = match.group(1).strip()
    print(f"\nüß† Processing new character:\n{character_sheet[:100]}...")

    character_results = {}

    for topic in topics:
        print(f"\nüî∏ Topic: {topic}")

        # Persona response
        persona_prompt = (
            f"You are roleplaying as the person described below.\n"
            f"Respond to the topic exactly how they would in a casual chatroom or text message.\n\n"
            f"Character Sheet:\n{character_sheet}\n\n"
            f"Topic:\n{topic}\n\n"
            f"Guidelines:\n"
            f"- Keep it brief (2‚Äì3 sentences max).\n"
            f"- Use natural, informal language like a real person.\n"
            f"- Make sure you highlight the personality described in the character sheet, your job is to roleplay as a character not just a normal person.\n"
            f"- Avoid overly structured or formal phrasing.\n"
            f"- No generic intros (e.g., 'That's an interesting question.')\n"
            f"- Avoid phrases like 'I believe', 'It would be', 'Personally', 'As someone who...'\n"
            f"- Write like you're actually chatting, not like you're writing a speech or essay.\n"
            f"- Use contractions, personality, and a touch of messiness‚Äîhumans aren't perfect.\n"
            f"Example:\n"
            f"Topic: What's one thing you'd bring on a deserted island?\n"
            f"Bad (too LLM-ish): \"If I had to choose one thing to bring to a deserted island, it would be a multi-tool because it is extremely versatile and would increase my chances of survival.\"\n"
            f"Good: \"My dog. Not super useful, but I wouldn‚Äôt go crazy alone.\"\n\n"
            f"Now give the response:"
        )

        persona_response = call_with_backoff(
            client.chat.completions.create,
            model="gpt-4.5-preview",
            messages=[{"role": "user", "content": persona_prompt}],
            temperature=0.9,
            max_completion_tokens=max_tokens,
            logit_bias=logit_bias
        )

        persona_output = persona_response.choices[0].message.content.strip()
        print(f"Initial: {persona_output}")

        # Critique
        critic_prompt = (
            f"You are a psychologist trained in assessing whether a given response was generated by a human or an LLM.\n\n"
            f"Character Sheet:\n{character_sheet}\n\n"
            f"Topic:\n{topic}\n\n"
            f"Response:\n{persona_output}\n\n"
            f"If the response seems LLM-like, give a very brief explanation of why, and instructions for the LLM to use to refine its response.\n"
            f"If the response seems like it was generated by a human, just simply state that it is sufficiently humanlike."
        )

        critic_response = call_with_backoff(
            client.chat.completions.create,
            model="o3-mini",
            messages=[{"role": "user", "content": critic_prompt}],
            max_completion_tokens=max_tokens
        )

        critique = critic_response.choices[0].message.content.strip()

        # Refine
        refine_prompt = (
            f"Refine the following response based on this critique to better align with the character sheet and sound more humanlike.\n\n"
            f"If the critique says the original response is sufficiently humanlike, just repeat the original output word for word.\n\n"
            f"Character Sheet:\n{character_sheet}\n\n"
            f"Topic:\n{topic}\n\n"
            f"Original Response:\n{persona_output}\n\n"
            f"Critique:\n{critique}\n\n"
            f"Revised Response (no more than 2‚Äì3 sentences):"
        )

        refined_response = call_with_backoff(
            client.chat.completions.create,
            model="gpt-4.5-preview",
            messages=[{"role": "user", "content": refine_prompt}],
            temperature=0.5,
            max_tokens=max_tokens,
            logit_bias=logit_bias
        )

        final_output = refined_response.choices[0].message.content.strip()
        print(f"Refined: {final_output}")

        character_results[topic] = {
            "initial": persona_output,
            "refined": final_output
        }

    results[character_sheet] = character_results

# === Save to JSON ===
with open(output_file, "w") as f:
    json.dump(results, f, indent=4)

print(f"\n‚úÖ All results saved to {output_file}")
